# -*- coding: utf-8 -*-
"""Churn_py_v2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ws_3joytrhplsID5TxJS6vznB-0EmVGL
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/telco.csv", na_values=['NA','?','-'])

df.head()

df.info()

df['Churn Label'] = df['Churn Label'].map({'Yes': 1, 'No': 0})

df.head()

# List of columns to drop
columns_to_drop = ['Customer ID','Country','Population','Referred a Friend','Dependents', 'State', 'City', 'Zip Code', 'Latitude', 'Longitude','Quarter', 'Churn Category', 'Churn Reason']

# Check which columns exist in the DataFrame
existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]

# Drop the existing columns
df.drop(existing_columns_to_drop, axis=1, inplace=True)

df.head()

df.isnull().sum()

plt.figure(figsize=(5,4))
sns.countplot(df, x="Churn Label", palette="Set1")
plt.title("Churn Distribution")
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(12,8))
sns.histplot(df, x="Tenure in Months", hue="Churn Label", multiple="stack", ax=axes[0,0], palette="Set1")
axes[0,0].set_title("Tenure vs Churn")

sns.histplot(df, x="Monthly Charge", hue="Churn Label", multiple="stack", ax=axes[0,1], palette="Set1")
axes[0,1].set_title("Monthly Charge vs Churn")

sns.histplot(df, x="Total Charges", hue="Churn Label", multiple="stack", ax=axes[1,0], palette="Set1")
axes[1,0].set_title("Total Charges vs Churn")

sns.histplot(df, x="CLTV", hue="Churn Label", multiple="stack", ax=axes[1,1], palette="Set1")
axes[1,1].set_title("CLTV vs Churn")

plt.tight_layout()
plt.show()

num_cols = df.select_dtypes(include=['int64','float64']).columns
plt.figure(figsize=(10,6))
sns.heatmap(df[num_cols].corr(), cmap="coolwarm", annot=False)
plt.title("Correlation Heatmap (Numerical Features)")
plt.show()

imp_col = ["Contract", "Internet Service", "Payment Method", "Gender", "Senior Citizen"]

fig, axes = plt.subplots(2, 3, figsize=(16,8))

for i, col in enumerate(imp_col):
    ax = axes[i//3, i%3]
    sns.countplot(data=df, x=col, hue="Churn Label", palette="Set1", ax=ax)
    ax.set_title(f"{col} vs Churn")
    ax.tick_params(axis='x', rotation=20)
fig.delaxes(axes[1,2])
plt.tight_layout()
plt.show()

"""Correcting the imbalance of the column - Churn Label"""

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Features & target
X = df.drop("Churn Label", axis=1)
y = df["Churn Label"] # Target is already encoded

# Identify categorical columns
categorical_cols = X.select_dtypes(include='object').columns

# Create a column transformer for one-hot encoding
preprocessor = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ],
    remainder='passthrough' # Keep other columns as they are
)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Apply preprocessing to training data
X_train_processed = preprocessor.fit_transform(X_train)

# Apply SMOTE (oversample minority class)
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train_processed, y_train)


print("Original training set shape:", y_train.value_counts())
print("Balanced training set shape:", y_train_bal.value_counts())

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5, 10]
}

grid = GridSearchCV(
    estimator= RandomForestClassifier(random_state=42, class_weight='balanced'),
    param_grid=param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1
)

grid.fit(X_train_bal, y_train_bal)
best_model = grid.best_estimator_

print("✅ Best Params:", grid.best_params_)
print("✅ Best CV F1-Score:", grid.best_score_)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score

from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, roc_curve

# Smaller, randomized search space
param_dist = {
    'n_estimators': [100, 150],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

rf = RandomForestClassifier(random_state=42, class_weight='balanced')

# Randomized search with only 15 iterations
rand_search = RandomizedSearchCV(
    rf, param_distributions=param_dist,
    n_iter=15, cv=3, scoring='f1', n_jobs=-1, random_state=42, verbose=1
)

rand_search.fit(X_train_bal, y_train_bal)
best_rf = rand_search.best_estimator_

# --- Evaluate on test set ---
# Transform X_test using the fitted preprocessor
X_test_processed = preprocessor.transform(X_test)
y_proba = best_rf.predict_proba(X_test_processed)[:,1]
y_pred_default = (y_proba >= 0.5).astype(int)

print("Default Threshold (0.5):")
print(classification_report(y_test, y_pred_default))
print("ROC AUC:", roc_auc_score(y_test, y_proba))

# --- Threshold tuning ---
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
j_scores = tpr - fpr
best_thresh = thresholds[np.argmax(j_scores)]

y_pred_tuned = (y_proba >= best_thresh).astype(int)

print("\nBest Threshold:", best_thresh)
print("After Threshold Tuning:")
print(classification_report(y_test, y_pred_tuned))

print("\nAccuracy:", accuracy_score(y_test, y_pred_tuned))

conf_matrix = confusion_matrix(y_test, y_pred_tuned)

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Not Churned', 'Churned'],
            yticklabels=['Not Churned', 'Churned'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix (Tuned Threshold)')
plt.show()

df.head()

